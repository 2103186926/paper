

## 1. API序列特征 (32维)

这部分特征关注用户调用的API序列本身，试图从中发现异常模式。

*   **提取方法 (`_extract_api_sequence_features`)**:
    *   **API频率特征 (8维)**:
        *   统计日志中所有API调用的频率。
        *   选取频率最高的8个API。
        *   计算这8个API各自的调用次数占总调用次数的比例，作为前8维特征。
    *   **API序列模式特征 (8维)**:
        *   提取所有相邻API调用对（Bigrams），例如 "query\_spatial\_grid\_data -> query\_spatial\_grid\_data"。
        *   统计每种API调用对的出现频率。
        *   选取频率最高的8个API调用对。
        *   计算这8个调用对各自的出现次数占总调用对数量的比例，作为接下来的8维特征。
    *   **API调用多样性特征 (8维)**:
        *   **唯一API比例**: 计算日志中出现的唯一API种类数量与总API调用次数的比例。
        *   **平均会话API多样性**: 对每个会话，计算其内部唯一API种类数量与该会话总调用次数的比例，然后取所有会话该比例的平均值。
        *   **会话间API相似度 (Jaccard)**: 计算不同会话API集合之间的Jaccard相似系数的平均值（衡量不同会话行为的相似性）。
        *   **API类型比例**: 分别计算查询类 (`query`)、导出类 (`export`)、可视化类 (`visualization`) API调用次数占总调用次数的比例。
        *   **异常API比例**: 计算不在预定义常见API列表 (`common_apis`) 中的API调用次数占总调用次数的比例。
        *   **最大连续相同API比例**: 对每个会话，找到最长连续相同API调用的长度，计算其与该会话总长度的比值，然后取所有会话该比值的平均值。
    *   **Word2Vec特征 (8维)**:
        *   将每个会话的API调用序列视为一个句子。
        *   使用这些句子训练一个Word2Vec模型 (vector\_size=8, window=3, min\_count=1, sg=1)。
        *   计算日志中所有唯一API对应向量的平均值，得到一个8维向量作为特征。如果训练失败或API不在模型词汇表中，则使用零向量。

## 2. 时间行为特征 (16维)

这部分特征分析API调用的时间分布和时间参数，用于检测时间相关的异常，如短时爆频、非工作时间访问、查询未来数据等。

*   **提取方法 (`_extract_temporal_features`)**:
    *   **API调用频率 (4维)**:
        *   计算相邻API调用之间的时间差（秒）。
        *   提取平均调用间隔、最小调用间隔、调用间隔的标准差，并进行标准化。
        *   计算调用间隔的变异系数（标准差/平均值），并标准化。
    *   **短时大量请求 (3维)**:
        *   按分钟聚合请求。
        *   计算每分钟的最大请求数、平均请求数，并标准化。
        *   计算请求量的峰谷比（最大值/平均值），并标准化。
    *   **访问时间模式 (3维)**:
        *   计算工作时间（9:00-18:00）内的请求比例。
        *   计算深夜时间（23:00-6:00）内的请求比例。
        *   计算周末（周六、周日）的请求比例。
    *   **时间范围参数 (3维)**: (基于 `params['temporal_range']`)
        *   计算请求结束时间晚于当前时间的比例（未来数据请求）。
        *   计算请求开始时间早于当前时间5年以上的比例（远古历史数据请求）。
        *   计算请求时间跨度大于1年的比例（大时间跨度请求）。
    *   **突发性与周期性 (3维)**:
        *   计算最长连续短间隔（<5秒）请求序列的长度，并标准化。
        *   计算短间隔（<5秒）请求占总请求的比例。
        *   计算请求发生的小时分布的熵，并标准化（衡量访问时间的随机性/周期性）。

## 3. 空间行为特征 (16维)

这部分特征分析API调用涉及的空间范围和分辨率参数，用于检测空间相关的异常，如大范围扫描、高精度探测、不规则空间移动等。

*   **提取方法 (`_extract_spatial_features`)**:
    *   **空间范围面积 (7维)**: (基于 `params['spatial_range']`)
        *   计算每个请求的空间范围面积（经度差 \* 纬度差）。
        *   提取平均请求面积、最大请求面积、最小请求面积（反向标准化），并标准化。
        *   计算面积的变异系数，并标准化。
        *   计算面积大于10000（近似全球）、小于0.01（约1km²）、小于0.0001（点状）的请求比例。
    *   **空间分辨率 (5维)**: (基于 `params['spatial_resolution']`)
        *   统计高分辨率(<0.01)、中分辨率(0.01-0.1)、低分辨率(>=0.1)请求的比例。
        *   计算平均分辨率（反向标准化），并标准化。
        *   计算分辨率的变异系数，并标准化。
    *   **空间范围变化 (4维)**: (基于 `params['spatial_range']`)
        *   计算每个请求空间范围的中心点。
        *   计算连续请求中心点之间的移动距离（欧氏距离）。
        *   提取平均移动距离、最大移动距离，并标准化。
        *   计算连续请求中心点距离小于0.001（几乎未移动）的比例。
        *   计算中心点移动距离大于5度（大幅跳跃）的比例。

## 4. 数据量特征 (16维)

这部分特征关注API调用的响应大小和计算时间，用于检测资源滥用型异常，如请求超大数据量、导致长时间计算等。

*   **提取方法 (`_extract_data_volume_features`)**:
    *   **响应大小 (6维)**: (基于 `response_size`)
        *   计算平均响应大小(MB)、最大响应大小(MB)、总响应大小(GB)，并标准化。
        *   计算响应大小大于100MB的比例。
        *   计算响应大小小于1MB的比例。
        *   计算响应大小的变异系数，并标准化。
    *   **计算时间 (6维)**: (基于 `compute_time`)
        *   计算平均计算时间(秒)、最大计算时间(秒)、总计算时间(分钟)，并标准化。
        *   计算计算时间大于30秒的比例。
        *   计算计算时间小于5秒的比例。
        *   计算计算时间的变异系数，并标准化。
    *   **数据吞吐量 (4维)**: (计算 `response_size` / `compute_time`)
        *   计算平均吞吐量(MB/s)、最大吞吐量(MB/s)，并标准化。
        *   计算吞吐量大于10MB/s的比例。
        *   计算吞吐量的变异系数，并标准化。

## 5. 会话行为特征 (16维)

这部分特征从会话（Session）的角度分析用户行为，检测与会话相关的异常，如大量短会话、超长会话、会话内高频操作等。

*   **提取方法 (`_extract_session_features`)**:
    *   **会话基本统计 (6维)**:
        *   计算会话数量，并标准化。
        *   计算每个会话的API调用次数（会话长度）。
        *   提取平均会话长度、最长会话长度，并标准化。
        *   计算会话长度的变异系数，并标准化。
        *   计算只包含1次调用的会话比例。
        *   计算长度大于50次调用的会话比例。
    *   **会话时间统计 (5维)**:
        *   计算每个会话的持续时间（最后一次调用时间 - 第一次调用时间）。
        *   提取平均会话持续时间(分钟)、最长会话持续时间(分钟)，并标准化。
        *   计算会话持续时间的变异系数，并标准化。
        *   计算持续时间小于5分钟的会话比例。
        *   计算持续时间大于30分钟的会话比例。
    *   **会话调用频率 (4维)**:
        *   计算每个会话内的平均调用频率（调用次数 / 持续时间）。
        *   提取平均会话调用频率(次/秒)、最高会话调用频率(次/秒)，并标准化。
        *   计算会话调用频率的变异系数，并标准化。
        *   计算调用频率大于0.05次/秒（即平均间隔小于20秒）的会话比例。
    *   **并发会话 (1维)**:
        *   按分钟聚合，计算每分钟同时活跃的会话数量。
        *   计算平均并发会话数，并标准化。

## 6. IP与设备特征 (16维)

这部分特征分析请求来源的IP地址和设备ID，用于检测伪造来源、共享账号、设备跳变等异常。

*   **提取方法 (`_extract_ip_device_features`)**:
    *   **IP地址特征 (5维)**: (基于 `ip`)
        *   计算唯一IP地址数量，并标准化。
        *   计算唯一IP数与总请求数的比例（IP变化率）。
        *   计算连续请求中IP地址发生变化的比例。
        *   计算请求次数最多的IP占总请求数的比例。
        *   计算IP地址分布的熵，并标准化（衡量IP使用的集中程度）。
    *   **设备ID特征 (5维)**: (基于 `device_id`)
        *   计算唯一设备ID数量，并标准化。
        *   计算唯一设备数与总请求数的比例（设备变化率）。
        *   计算连续请求中设备ID发生变化的比例。
        *   计算请求次数最多的设备占总请求数的比例。
        *   计算设备ID分布的熵，并标准化（衡量设备使用的集中程度）。
    *   **IP与设备关联 (6维)**:
        *   计算平均每个IP使用的唯一设备ID数量，并标准化。
        *   计算单个IP使用的最大唯一设备ID数量，并标准化。
        *   计算平均每个设备ID使用的唯一IP数量，并标准化。
        *   计算单个设备ID使用的最大唯一IP数量，并标准化。
        *   计算一个IP对应多个设备或一个设备对应多个IP的情况占比。
        *   计算IP-设备对联合分布的熵，并标准化（衡量IP和设备对应关系的混乱程度）。

## 7. 访问模式特征 (16维)

这部分特征综合分析请求状态、API类型分布、参数规律性等，用于捕捉更宏观的异常模式，如试探性攻击、自动化爬取等。

*   **提取方法 (`_extract_pattern_features`)**:
    *   **请求状态 (3维)**: (基于 `status`)
        *   计算请求成功 (`success`) 的比例。
        *   计算请求失败 (`error`) 的比例。
        *   计算最长连续失败请求的次数，并标准化。
    *   **API类型分布 (4维)**: (基于 `api`)
        *   计算查询类 (`query`) API的比例。
        *   计算修改类 (`update`, `modify`, `create`, `delete`) API的比例。
        *   计算未来数据查询 (`future`) API的比例。
        *   计算API种类分布的熵，并标准化（衡量API使用类型的集中程度）。
    *   **数据类别分布 (2维)**: (基于 `params['data_category']`)
        *   计算数据类别分布的熵，并标准化。
        *   计算访问敏感数据类别（如温度、降水等）的比例。
    *   **行为模式 (4维)**:
        *   计算请求间隔时间的平均周期性得分（基于用户请求间隔变异系数的倒数）。
        *   计算整体请求频率（总请求数/总时间跨度），并标准化（衡量是否像爬虫）。
        *   计算请求空间范围的覆盖率（所有请求面积之和 / 总边界框面积 * 请求数）。
        *   计算API请求参数的多样性得分（唯一参数组合数量 / 总请求数）。
    *   **预留特征 (3维)**:
        *   保留3维零向量，以便未来扩展。

通过组合这7大类共计128维特征，可以从多个角度刻画用户的操作行为，为后续的深度学习模型检测恶意操作提供全面的输入信息。





